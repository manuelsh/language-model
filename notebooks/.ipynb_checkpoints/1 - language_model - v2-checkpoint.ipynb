{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1\n",
    "* Done in Tensorflow\n",
    "* Unfinished\n",
    "\n",
    "## v2\n",
    "* Done in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2016 NVIDIA Corporation\r\n",
      "Built on Tue_Jan_10_13:22:03_CST_2017\r\n",
      "Cuda compilation tools, release 8.0, V8.0.61\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2 (default, Sep 14 2017, 22:51:06) \\n[GCC 5.4.0 20160609]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from torch==0.3.0.post4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from torch==0.3.0.post4)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.5/dist-packages (from torchvision)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.5/dist-packages (from torchvision)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from torchvision)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from torchvision)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.5/dist-packages (from pillow>=4.1.1->torchvision)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from torch->torchvision)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl \n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files and put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 191 ms, total: 2.19 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_path = '../data/external/joke-dataset/'\n",
    "reddit_jokes = pd.read_json(data_path + 'reddit_jokes.json')\n",
    "wocka_jokes = pd.read_json(data_path + 'wocka.json' )\n",
    "stupid_jokes = pd.read_json(data_path + 'stupidstuff.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208345"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes['body'] = reddit_jokes['title'] + '\\n' + reddit_jokes['body']\n",
    "del reddit_jokes['title']\n",
    "jokes = pd.concat([reddit_jokes['body'], wocka_jokes['body'], stupid_jokes['body']], axis = 0, ignore_index=True)\n",
    "len(jokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = jokes[~(jokes=='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no nulls and no empty\n",
    "assert sum(jokes=='')==0\n",
    "assert sum(jokes.isnull())==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "jokes = jokes.apply(lambda x: x.lower())\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a young alabama man goes to a drug store and says to the pharmacist: \"i got a hot date tonight, an' i need me some pertection. how much is a pack a' them thar rubbers gonna cost me?\" the pharmacist responds: \"a three-pack of condoms is $4.99 with tax.\" \"tacks!\" the shocked redneck says. \"gawd a' mighty, don't they stay on by themselves?\n",
      "-----\n",
      "i'm a good, god fearing person, i don't drink, smoke, or cuss.\n",
      "god damnit, i left my cigarettes at the bar.\n",
      "-----\n",
      "what do you call a woman with an opinion??\n",
      "wrong\n",
      "-----\n",
      "can't remember, does anyone remember the joke about the nut behind the wheel?\n",
      "i am trying to remember it but i can't. it was something about a taxi driver and he didn't speak the language, and the kick was\" tell your boss to fix the loose but behind the wheel\".  if you remember can you please post it for me here?\n",
      "-----\n",
      "did you know if a person farts too much their ass turns blue!\n",
      "it's from the methane, just look at uranus!\n",
      "-----\n",
      "there's a special place in hell for the disabled,\n",
      "but it's more of a zoning ordinance and safety code thing.\n",
      "-----\n",
      "an arab sheik was admitted to hospital for heart surgery.\n",
      "but prior to the surgery, the doctors needed to store his blood in case a need arose. \n",
      "\n",
      "as the gentleman had a rare type of blood, it couldn't be found locally, so the call went out.\n",
      "\n",
      "finally a scotsman was located who had a similar blood type. the scot willingly donated his blood for the arab.\n",
      "\n",
      "after the surgery, the arab sent the scotsman as appreciation for giving his blood, a new bmw motorcycle, diamonds and a substantial sum of money.\n",
      "\n",
      "a couple of days later, the arab had to go through a corrective surgery.\n",
      "\n",
      "his doctor telephoned the scotsman who was more than happy to donate his blood again.\n",
      "\n",
      "after the second surgery, the arab sent the scotsman a thank-you card and a box of quality street chocolates.\n",
      "\n",
      "the scotsman was shocked that the arab did not reciprocate his kind gesture as he had anticipated.\n",
      "\n",
      "he phoned the arab and asked him: \"i thought you would be generous again, that you would give me another motorcycle, diamonds & money... but you only gave me a thank-you card & a box of quality street chocolates.\"\n",
      "\n",
      "to this the arab replied: \"aye laddie, but i now have scottish blood in ma veins\".\n",
      "-----\n",
      "last night me and my girlfriend watched three dvds back to back\n",
      "luckily i was the one facing the tv\n",
      "-----\n",
      "what is brown and sticky?\n",
      "a stick.\n",
      "-----\n",
      "how many \"sup dude\"s does it take to screw in a lightbulb?\n",
      "none, it's already lit fam.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(random.choice(jokes))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in training and cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need, language model\n",
    "\n",
    "# # Shuffle sample\n",
    "# jokes_index=list(jokes.index)\n",
    "# random.shuffle(jokes_index)\n",
    "# jokes = jokes.iloc[jokes_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split\n",
    "# percentage_validation = 0.2\n",
    "# cut_row = int(len(jokes)*(1.-percentage_validation))\n",
    "# train_set = jokes[0:cut_row].reset_index(drop=True)\n",
    "# val_set = jokes[cut_row:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tokens and encode train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time token_frequencies = Counter([item for sublist in jokes for item in sublist])\n",
    "# len(token_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Create token_dict based in ranking, and eliminate token with less than certain threshold\n",
    "# freq_threshold = 20\n",
    "# token_ranked_df = pd.DataFrame([[token, token_frequencies[token] ] for token in token_frequencies if token_frequencies[token]>freq_threshold])\\\n",
    "#                             .sort_values(1, ascending = False).reset_index()[[0]]\n",
    "# token_dict = {token:freq for token,freq in zip( list(token_ranked_df[0]), list(token_ranked_df.index) )}\n",
    "\n",
    "# token_dict['<end>']=len(token_dict)\n",
    "# decoder_dict = {token_dict[k]:k for k in token_dict.keys()}\n",
    "# tokens_count = len(token_dict)\n",
    "# tokens_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create token_dict based on ascii letters\n",
    "all_letters = string.ascii_letters[0:26] + \"\"\" \".,;'-+=?!$%():\\n\"\"\"\n",
    "token_dict = {token:k for token,k in zip(all_letters, range(len(all_letters)))}\n",
    "token_dict['<end>']=len(token_dict)\n",
    "decoder_dict = {token_dict[k]:k for k in token_dict.keys()}\n",
    "tokens_count = len(token_dict)\n",
    "tokens_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.08 s, sys: 247 ms, total: 9.33 s\n",
      "Wall time: 9.34 s\n"
     ]
    }
   ],
   "source": [
    "def text_encoder(text):\n",
    "    return [token_dict[token] for token in text if token in token_dict] + [token_dict['<end>']]\n",
    "\n",
    "%time jokes_encoded =  list( jokes.apply(text_encoder) ) # as a list is much faster to retrieve elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 tokens_count,\n",
    "                 embedding_dimension, \n",
    "                 rnn_dim, \n",
    "                 num_layers, \n",
    "                 dropout):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn_dim = rnn_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(tokens_count, embedding_dimension)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_dimension, \n",
    "                            hidden_size = rnn_dim, \n",
    "                            num_layers = num_layers, \n",
    "                            dropout = dropout,\n",
    "                            batch_first = True)\n",
    "        \n",
    "        self.linear = nn.Linear( rnn_dim , tokens_count)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, inp, hidden, train=True):\n",
    "        embedded = self.embedding(inp).view(1, -1, embedding_dimension)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.linear(output)\n",
    "        if train: output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initRNN(self):\n",
    "        result = (Variable(torch.zeros(num_layers, batch_size, self.rnn_dim)), \n",
    "                Variable(torch.zeros(num_layers, batch_size, self.rnn_dim)))\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "embedding_dimension = 512\n",
    "num_layers = 4\n",
    "rnn_dim = 256\n",
    "\n",
    "dropout = 0.1\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(tokens_count, embedding_dimension, rnn_dim, num_layers, dropout)\n",
    "loss_function = nn.NLLLoss()\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters count: 16516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of RNN(\n",
       "  (embedding): Embedding(44, 512)\n",
       "  (lstm): LSTM(512, 256, num_layers=4, batch_first=True, dropout=0.1)\n",
       "  (linear): Linear(in_features=256, out_features=44)\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (softmax): LogSoftmax()\n",
       ")>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of parameters\n",
    "parameters_count=0\n",
    "for a in rnn.parameters():\n",
    "    parameters_count+=len(a)\n",
    "print(\"Parameters count: %d\" %parameters_count)\n",
    "rnn.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "# Generates a sequence\n",
    "def generates_sequence(start_character, max_length):\n",
    "    hidden = rnn.initRNN()\n",
    "    next_token = Variable(torch.LongTensor([token_dict[start_character]]))\n",
    "    top_index = 0\n",
    "\n",
    "    new_text = start_character\n",
    "\n",
    "    while top_index != token_dict['<end>']:\n",
    "        output, hidden = rnn(next_token , hidden, train = False)\n",
    "        top_index = int(output.data.topk(1)[1][0])\n",
    "#        print(output)\n",
    "#        print(hidden)\n",
    "        new_text+=decoder_dict[top_index]\n",
    "        if len(new_text)>=max_length: break\n",
    "\n",
    "    return new_text\n",
    "\n",
    "print(generates_sequence('w', 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoded_text):\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = rnn.initRNN()\n",
    "\n",
    "    text_length = len(encoded_text)\n",
    "    for i in range(text_length-1):\n",
    "        x_token = Variable( torch.LongTensor([encoded_text[i]]) )\n",
    "        y_token = Variable( torch.LongTensor([encoded_text[i+1]]))\n",
    "\n",
    "        output, hidden = rnn(x_token, hidden)\n",
    "        loss += loss_function(output.view(1,-1), y_token)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    return output, loss.data[0] / x_token.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    random.shuffle(jokes_encoded)\n",
    "    #pbar =  tqdm(jokes_encoded)\n",
    "    for text in jokes_encoded:\n",
    "        output, loss = train(text)\n",
    "        total_loss += loss\n",
    "        \n",
    "#         if counter % print_every == 0:\n",
    "#             #pbar.write('Step: (%d) Loss: %.4f' % ( counter, total_loss / plot_every))\n",
    "#             print('---')\n",
    "#             print('Step: (%d)' % ( counter))\n",
    "#             print(generates_sequence(random.choice(string.ascii_letters[0:26]), 500))\n",
    "#             print('---')\n",
    "#             print(generates_sequence(random.choice(string.ascii_letters[0:26]), 500))\n",
    "#             print('---')\n",
    "#             print(generates_sequence(random.choice(string.ascii_letters[0:26]), 500))\n",
    "#             print('---')\n",
    "            \n",
    "        if counter % plot_every == 0:\n",
    "            print('Step: (%d) Loss: %.4f' % ( counter, total_loss / plot_every))\n",
    "            all_losses.append(total_loss / plot_every)\n",
    "            total_loss = 0\n",
    "\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37098"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
